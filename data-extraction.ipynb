{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df6ead26",
   "metadata": {
    "_cell_guid": "be42129a-ecac-40ca-a068-fb1364bf413a",
    "_uuid": "7116824f-cda3-4699-8cf4-c2856664a171",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-12-16T08:57:28.482185Z",
     "iopub.status.busy": "2023-12-16T08:57:28.481420Z",
     "iopub.status.idle": "2023-12-16T08:57:30.641998Z",
     "shell.execute_reply": "2023-12-16T08:57:30.639920Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.171749,
     "end_time": "2023-12-16T08:57:30.645956",
     "exception": false,
     "start_time": "2023-12-16T08:57:28.474207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "@author: Nieto Nicol√°s\r\n",
    "@email: nnieto@sinc.unl.edu.ar\r\n",
    "\r\n",
    "Utilitys from extract, read and load data from Inner Speech Dataset\r\n",
    "\"\"\"\r\n",
    "            \r\n",
    "import mne\r\n",
    "import gc\r\n",
    "import numpy as np\r\n",
    "from utilitys import sub_name , unify_names\r\n",
    "import pickle\r\n",
    "def Extract_subject_from_BDF(root_dir,N_S,N_B):\r\n",
    "\r\n",
    "    # name correction if N_Subj is less than 10\r\n",
    "    Num_s = sub_name(N_S)\r\n",
    "    \r\n",
    "    #  load data\r\n",
    "    file_name = root_dir + '/' + Num_s + '/ses-0'+ str(N_B) +'/eeg/' +Num_s+'_ses-0'+str(N_B)+'_task-innerspeech_eeg.bdf'\r\n",
    "    rawdata = mne.io.read_raw_bdf(input_fname=file_name, preload=True,verbose='WARNING')\r\n",
    "    return rawdata , Num_s\r\n",
    "\r\n",
    "\r\n",
    "def Extract_data_from_subject(root_dir,N_S,datatype):\r\n",
    "    \r\n",
    "    \"\"\"\r\n",
    "    Load all blocks for one subject and stack the results in X\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    data=dict()\r\n",
    "    y=dict()\r\n",
    "    N_B_arr=[1,2,3]\r\n",
    "    datatype=datatype.lower()\r\n",
    "    \r\n",
    "    for N_B in N_B_arr:\r\n",
    "        # name correction if N_Subj is less than 10\r\n",
    "        Num_s = sub_name(N_S)   \r\n",
    "            \r\n",
    "        y[N_B] = load_events(root_dir,N_S,N_B)\r\n",
    "        \r\n",
    "        if datatype==\"eeg\":\r\n",
    "            #  load data and events\r\n",
    "            file_name = root_dir + '/derivatives/' + Num_s + '/ses-0'+ str(N_B) + '/' +Num_s+'_ses-0'+str(N_B)+'_eeg-epo.fif'\r\n",
    "            X= mne.read_epochs(file_name,verbose='WARNING')\r\n",
    "            data[N_B]= X._data\r\n",
    "            \r\n",
    "        elif datatype==\"exg\":\r\n",
    "            file_name = root_dir + '/derivatives/' + Num_s + '/ses-0'+ str(N_B) + '/' +Num_s+'_ses-0'+str(N_B)+'_exg-epo.fif'\r\n",
    "            X= mne.read_epochs(file_name,verbose='WARNING')\r\n",
    "            data[N_B]= X._data\r\n",
    "        \r\n",
    "        elif datatype==\"baseline\":\r\n",
    "            file_name = root_dir + '/derivatives/' + Num_s + '/ses-0'+ str(N_B) + '/' +Num_s+'_ses-0'+str(N_B)+'_baseline-epo.fif'\r\n",
    "            X= mne.read_epochs(file_name,verbose='WARNING')\r\n",
    "            data[N_B]= X._data\r\n",
    "\r\n",
    "        else:\r\n",
    "            raise Exception(\"Invalid Datatype\")\r\n",
    "         \r\n",
    "    X = np.vstack((data.get(1),data.get(2),data.get(3))) \r\n",
    "    \r\n",
    "    \r\n",
    "    Y = np.vstack((y.get(1),y.get(2),y.get(3))) \r\n",
    "    \r\n",
    "\r\n",
    "    return X, Y\r\n",
    "\r\n",
    "def Extract_block_data_from_subject(root_dir,N_S,datatype,N_B):\r\n",
    "    \"\"\"\r\n",
    "    Load selected block from one subject\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "\r\n",
    "    # Get subject name\r\n",
    "    Num_s = sub_name(N_S)\r\n",
    "        \r\n",
    "    # Get events\r\n",
    "    Y = load_events(root_dir,N_S,N_B)\r\n",
    "    \r\n",
    "    sub_dir = root_dir + '/derivatives/' + Num_s + '/ses-0'+ str(N_B) + '/' +Num_s+'_ses-0'+str(N_B)\r\n",
    "    if datatype == \"eeg\":\r\n",
    "        #  load EEG data \r\n",
    "        file_name = sub_dir + '_eeg-epo.fif'\r\n",
    "        X = mne.read_epochs(file_name,verbose='WARNING')\r\n",
    "\r\n",
    "    elif datatype==\"exg\":\r\n",
    "        #  load EXG data \r\n",
    "        file_name = sub_dir + '_exg-epo.fif'\r\n",
    "        X = mne.read_epochs(file_name,verbose='WARNING')\r\n",
    "    \r\n",
    "    elif datatype==\"baseline\":\r\n",
    "        #  load Baseline data \r\n",
    "        file_name = sub_dir + '_baseline-epo.fif'\r\n",
    "        X = mne.read_epochs(file_name,verbose='WARNING')\r\n",
    "    \r\n",
    "    else:\r\n",
    "        raise Exception(\"Invalid Datatype\")\r\n",
    "     \r\n",
    "    return X, Y\r\n",
    "\r\n",
    "def Extract_report(root_dir,N_B,N_S):\r\n",
    "\r\n",
    "\r\n",
    "    # Get subject name\r\n",
    "    Num_s = sub_name(N_S)\r\n",
    "        \r\n",
    "    # Save report\r\n",
    "    sub_dir = root_dir + '/derivatives/' + Num_s + '/ses-0'+ str(N_B) + '/' +Num_s+'_ses-0'+str(N_B)\r\n",
    "    file_name = sub_dir + '_report.pkl'\r\n",
    "    \r\n",
    "    with open(file_name, 'rb') as input:\r\n",
    "        report = pickle.load(input)\r\n",
    "\r\n",
    "    return report\r\n",
    "        \r\n",
    "\r\n",
    "def Extract_TFR(TRF_dir, Cond, Class, TFR_method , TRF_type):\r\n",
    "\r\n",
    "\r\n",
    "    # Unify names as stored\r\n",
    "    Cond, Class = unify_names(Cond, Class)       \r\n",
    "    \r\n",
    "    fname = TRF_dir + TFR_method + \"_\" + Cond + \"_\" + Class + \"_\"+TRF_type+\"-tfr.h5\"\r\n",
    "    \r\n",
    "    TRF = mne.time_frequency.read_tfrs (fname)[0]\r\n",
    "    \r\n",
    "    return TRF\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def Extract_data_multisubject(root_dir, N_S_list, datatype='EEG'):\r\n",
    "    \"\"\"\r\n",
    "    Load all blocks for a list of subject and stack the results in X\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "\r\n",
    "    N_B_arr = [1,2,3]\r\n",
    "    tmp_list_X = []\r\n",
    "    tmp_list_Y = []\r\n",
    "    rows = []\r\n",
    "    total_elem = len(N_S_list)*3 # assume 3 sessions per subject\r\n",
    "    S = 0\r\n",
    "    datatype=datatype.lower()\r\n",
    "    for N_S in N_S_list:\r\n",
    "        print(\"Iteration \", S)\r\n",
    "        print(\"Subject \", N_S)\r\n",
    "        for N_B in N_B_arr:\r\n",
    "    \r\n",
    "            Num_s = sub_name(N_S)\r\n",
    "\r\n",
    "            base_file_name = root_dir + '/derivatives/' + Num_s + '/ses-0'+ str(N_B) + '/' +Num_s+'_ses-0'+str(N_B) \r\n",
    "            events_file_name = base_file_name+'_events.dat'\r\n",
    "            data_tmp_Y = np.load(events_file_name,allow_pickle=True)\r\n",
    "            tmp_list_Y.append(data_tmp_Y)\r\n",
    "            print(\"Inner iteration \" , N_B)\r\n",
    "            if datatype==\"eeg\":\r\n",
    "                # load data and events\r\n",
    "                eeg_file_name = base_file_name+'_eeg-epo.fif'\r\n",
    "                data_tmp_X = mne.read_epochs(eeg_file_name,verbose='WARNING')._data\r\n",
    "                rows.append(data_tmp_X.shape[0])\r\n",
    "                if S == 0 and N_B == 1: # assume same number of channels, time steps, and column labels in every subject and session\r\n",
    "                  chann=data_tmp_X.shape[1]\r\n",
    "                  steps=data_tmp_X.shape[2]\r\n",
    "                  columns=data_tmp_Y.shape[1]\r\n",
    "                tmp_list_X.append(data_tmp_X)\r\n",
    "\r\n",
    "            elif datatype==\"exg\":\r\n",
    "                exg_file_name = base_file_name+'_exg-epo.fif'\r\n",
    "                data_tmp_X = mne.read_epochs(exg_file_name,verbose='WARNING')._data\r\n",
    "                rows.append(data_tmp_X.shape[0])\r\n",
    "                if S == 0 and N_B == 1:\r\n",
    "                  chann=data_tmp_X.shape[1]\r\n",
    "                  steps=data_tmp_X.shape[2]\r\n",
    "                  columns=data_tmp_Y.shape[1]\r\n",
    "                tmp_list_X.append(data_tmp_X)\r\n",
    "            \r\n",
    "            elif datatype==\"baseline\":\r\n",
    "                baseline_file_name = base_file_name+'_baseline-epo.fif'\r\n",
    "                data_tmp_X = mne.read_epochs(baseline_file_name,verbose='WARNING')._data\r\n",
    "                rows.append(data_tmp_X.shape[0])\r\n",
    "                if S == 0 and N_B == 1:\r\n",
    "                  chann=data_tmp_X.shape[1]\r\n",
    "                  steps=data_tmp_X.shape[2]\r\n",
    "                  columns=data_tmp_Y.shape[1]\r\n",
    "                tmp_list_X.append(data_tmp_X)\r\n",
    "    \r\n",
    "            else:\r\n",
    "                raise Exception(\"Invalid Datatype\")\r\n",
    "                return None, None\r\n",
    "        \r\n",
    "        S += 1\r\n",
    "\r\n",
    "    X = np.empty((sum(rows), chann, steps))\r\n",
    "    Y = np.empty((sum(rows), columns))\r\n",
    "    offset = 0\r\n",
    "    # put elements of list into numpy array\r\n",
    "    for i in range(total_elem):\r\n",
    "      print(\"Saving element {} into array \".format(i))\r\n",
    "      X[offset:offset+rows[i],:,:] = tmp_list_X[0]\r\n",
    "      if datatype==\"eeg\" or datatype==\"exg\":\r\n",
    "        Y[offset:offset+rows[i],:] = tmp_list_Y[0] # only build Y for the datatypes that uses it\r\n",
    "      offset+=rows[i]\r\n",
    "      del tmp_list_X[0]\r\n",
    "      del tmp_list_Y[0]\r\n",
    "      gc.collect()\r\n",
    "    print(\"X shape\", X.shape)\r\n",
    "    print(\"Y shape\", Y.shape)\r\n",
    "\r\n",
    "    if datatype==\"eeg\" or datatype==\"exg\":\r\n",
    "      # for eeg and exg types, there is a predefined label that is returned\r\n",
    "      return X,Y\r\n",
    "    else:\r\n",
    "      # for baseline datatypes, there's no such label (rest phase)\r\n",
    "      return X\r\n",
    "  \r\n",
    "def load_events(root_dir,N_S,N_B):\r\n",
    "    \r\n",
    "    Num_s = sub_name(N_S)\r\n",
    "    # Create file Name\r\n",
    "    file_name =root_dir+\"/derivatives/\"+Num_s+\"/ses-0\"+str(N_B)+\"/\"+Num_s+\"_ses-0\"+str(N_B)+\"_events.dat\"\r\n",
    "    # Load Events\r\n",
    "    events = np.load(file_name,allow_pickle=True)\r\n",
    "    \r\n",
    "    return events"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 155138881,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 155138978,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 155140329,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.5594,
   "end_time": "2023-12-16T08:57:31.475994",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-16T08:57:22.916594",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5729408,"sourceType":"datasetVersion","datasetId":3295125},{"sourceId":155230451,"sourceType":"kernelVersion"},{"sourceId":155230586,"sourceType":"kernelVersion"},{"sourceId":155230674,"sourceType":"kernelVersion"}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport shutil\nimport mne\nimport warnings\nimport datetime\n\n\nfrom data_extraction import  Extract_data_from_subject\nfrom data_processing import  Select_time_window, Transform_for_classificator, Split_trial_in_time\nfrom tensorflow.keras import layers, models\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom keras.constraints import max_norm\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\n\n\nnp.random.seed(23)\n\nmne.set_log_level(verbose='warning') #to avoid info at terminal\nwarnings.filterwarnings(action = \"ignore\", category = DeprecationWarning ) \nwarnings.filterwarnings(action = \"ignore\", category = FutureWarning ) \n\n\n#%load_ext tensorboard\n#%tensorboard --logdir logs","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:24:38.348556Z","iopub.execute_input":"2024-01-09T16:24:38.348897Z","iopub.status.idle":"2024-01-09T16:24:56.375975Z","shell.execute_reply.started":"2024-01-09T16:24:38.348865Z","shell.execute_reply":"2024-01-09T16:24:56.375046Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Notes on Data Extraction:\n\n### Parameters\n> - Sampling Rate (fs) = 256\n> - data type: eeg, exg or baseline\n> - T-start: start of window (t=0: focus, t=0.5: arrow, t=1: cue (thinking), t=3.5: rest t=4.5: end)\n> - T-end: close of window\n> - N_S: subject number (1 through 10)\n> - N_B: Session (batch) number\n\n### Extract_subject_from_BDF(root_dir,N_S,N_B):\n\n> Loads raw data for subject and session. Takes the directory pointing to folder containing all recordings\n> and preprocessed files, subject number and session/batch number, and returns (raw data, subject number)\n\n### Extract_data_from_subject(root_dir,N_S,datatype):\n\n> Loads all blocks for one subject and stacks results. Takes the directory, calls the file for specified data \n> under the specified subject, and stacks all samples into one object. Also calls the labels. Returns (X,Y): \n> object with stacked trials/samples, and object with correlated labels.\n\n### Extract_block_data_from_subject(root_dir,N_S,datatype,N_B):\n\n> Does the same as above Extract_data_from_subject, but for a specified N_B (batch or session number).\n> returns (data samples, labels)\n\n### Extract_report(root_dir,N_B,N_S):\n\n> Pulls report with information regarding the given subject and session. Includes subject age, gender,\n> length of recording, count of correct and incorrect answer to control questions, position of contaminated\n> trials, mean power for EXG channels 7 & 8, and mean and STD for EXG 7 & 8 baseline recordings.\n\n### Extract_TFR(TRF_dir, Cond, Class, TFR_method , TRF_type):\n\n> Returns Time-Frequency Representation of specified condition and class. \n>\n> *Note: location of TRF data unclear, not likely to use in scope of project.*\n\n### Extract_data_multisubject(root_dir, N_S_list, datatype='EEG'):\n\n> Creates a stacked object of all sessions for all listed subjects and returns the stacked trials/samples\n> along with a stack of the corresponding labels.\n\n### load_events(root_dir,N_S,N_B):\n\n> Loads the events file to gather the label(s) for dataset using root directory, subject, and batch number.\n\n### Select_time_window(X,t_start=1, t_end=2.5, fs=256):\n\n> Cuts samples to desired time window.\n\n### Transform_for_classificator (X, Y, Classes, Conditions):\n\n> Pulls from the extracted dataset the trials and labels that correspond to the conditions and classes that\n> will be used for training and/or testing.\n","metadata":{}},{"cell_type":"code","source":"root_dir = '/kaggle/input/inner-speech-recognition/inner-speech-recognition'","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:41:30.809595Z","iopub.execute_input":"2024-01-09T16:41:30.810020Z","iopub.status.idle":"2024-01-09T16:41:30.815316Z","shell.execute_reply.started":"2024-01-09T16:41:30.809986Z","shell.execute_reply":"2024-01-09T16:41:30.814178Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"N_S = 1\ndatatype = 'eeg'\nTstart = 1.5\nTend = 3.5\nfs = 256\n\nX,Y = Extract_data_from_subject(root_dir,N_S,datatype)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:41:31.377470Z","iopub.execute_input":"2024-01-09T16:41:31.377856Z","iopub.status.idle":"2024-01-09T16:41:33.710976Z","shell.execute_reply.started":"2024-01-09T16:41:31.377823Z","shell.execute_reply":"2024-01-09T16:41:33.709983Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"Subj = Select_time_window(X = X, t_start = Tstart, t_end = Tend, fs = fs)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:41:33.712521Z","iopub.execute_input":"2024-01-09T16:41:33.713036Z","iopub.status.idle":"2024-01-09T16:41:33.717768Z","shell.execute_reply.started":"2024-01-09T16:41:33.712997Z","shell.execute_reply":"2024-01-09T16:41:33.716562Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"X_1, Y_1 = Transform_for_classificator(X = Subj, Y = Y, Classes = [['ALL']], Conditions = [['Vis']])","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:41:35.261460Z","iopub.execute_input":"2024-01-09T16:41:35.262153Z","iopub.status.idle":"2024-01-09T16:41:35.304462Z","shell.execute_reply.started":"2024-01-09T16:41:35.262115Z","shell.execute_reply":"2024-01-09T16:41:35.303250Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"X_2, Y_2 = Transform_for_classificator(X = Subj, Y = Y, Classes = [['ALL']], Conditions = [['Inner']])","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:41:37.926547Z","iopub.execute_input":"2024-01-09T16:41:37.926925Z","iopub.status.idle":"2024-01-09T16:41:37.968540Z","shell.execute_reply.started":"2024-01-09T16:41:37.926895Z","shell.execute_reply":"2024-01-09T16:41:37.967496Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"X_2.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:25:02.635918Z","iopub.execute_input":"2024-01-09T16:25:02.636293Z","iopub.status.idle":"2024-01-09T16:25:02.645380Z","shell.execute_reply.started":"2024-01-09T16:25:02.636262Z","shell.execute_reply":"2024-01-09T16:25:02.644320Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(200, 128, 512)"},"metadata":{}}]},{"cell_type":"code","source":"X = np.concatenate((X_1, X_2), axis=0)\nY = np.concatenate((Y_1, Y_2), axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:10.599873Z","iopub.execute_input":"2024-01-09T16:43:10.600302Z","iopub.status.idle":"2024-01-09T16:43:10.683794Z","shell.execute_reply.started":"2024-01-09T16:43:10.600264Z","shell.execute_reply":"2024-01-09T16:43:10.682838Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:12.895113Z","iopub.execute_input":"2024-01-09T16:43:12.895998Z","iopub.status.idle":"2024-01-09T16:43:12.902863Z","shell.execute_reply.started":"2024-01-09T16:43:12.895957Z","shell.execute_reply":"2024-01-09T16:43:12.901689Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"(400, 128, 512)"},"metadata":{}}]},{"cell_type":"code","source":"Y.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:14.300382Z","iopub.execute_input":"2024-01-09T16:43:14.300764Z","iopub.status.idle":"2024-01-09T16:43:14.307570Z","shell.execute_reply.started":"2024-01-09T16:43:14.300732Z","shell.execute_reply":"2024-01-09T16:43:14.306599Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"(400, 4)"},"metadata":{}}]},{"cell_type":"code","source":"Y[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:49:01.007767Z","iopub.execute_input":"2024-01-09T16:49:01.008192Z","iopub.status.idle":"2024-01-09T16:49:01.016259Z","shell.execute_reply.started":"2024-01-09T16:49:01.008157Z","shell.execute_reply":"2024-01-09T16:49:01.015292Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"array([1121166,       0,       2,       1])"},"metadata":{}}]},{"cell_type":"code","source":"input_shape = (X.shape[1],X.shape[2],1)\nprint(input_shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:14.882249Z","iopub.execute_input":"2024-01-09T16:43:14.883764Z","iopub.status.idle":"2024-01-09T16:43:14.890519Z","shell.execute_reply.started":"2024-01-09T16:43:14.883713Z","shell.execute_reply":"2024-01-09T16:43:14.889289Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"(128, 512, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# one-hot encoding\nY[:,(0,1)].shape\n# print(Labels_2_inner[:,(0,1)])\nlabels = Y[:,1]\ny = pd.get_dummies(labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:15.063585Z","iopub.execute_input":"2024-01-09T16:43:15.064805Z","iopub.status.idle":"2024-01-09T16:43:15.071926Z","shell.execute_reply.started":"2024-01-09T16:43:15.064754Z","shell.execute_reply":"2024-01-09T16:43:15.070663Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"y[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:49:34.586975Z","iopub.execute_input":"2024-01-09T16:49:34.587397Z","iopub.status.idle":"2024-01-09T16:49:34.597900Z","shell.execute_reply.started":"2024-01-09T16:49:34.587364Z","shell.execute_reply":"2024-01-09T16:49:34.596705Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"0       True\n1      False\n2      False\n3      False\n4       True\n       ...  \n395    False\n396    False\n397    False\n398    False\n399    False\nName: 0, Length: 400, dtype: bool"},"metadata":{}}]},{"cell_type":"code","source":"Adquisition_eq=\"biosemi128\"\nmontage = mne.channels.make_standard_montage(Adquisition_eq)\ninfo = mne.create_info(ch_names=X.shape[1], sfreq=256, ch_types='eeg')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:15.318810Z","iopub.execute_input":"2024-01-09T16:43:15.319212Z","iopub.status.idle":"2024-01-09T16:43:15.335709Z","shell.execute_reply.started":"2024-01-09T16:43:15.319177Z","shell.execute_reply":"2024-01-09T16:43:15.334562Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"montage","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:15.461002Z","iopub.execute_input":"2024-01-09T16:43:15.463695Z","iopub.status.idle":"2024-01-09T16:43:15.470006Z","shell.execute_reply.started":"2024-01-09T16:43:15.463635Z","shell.execute_reply":"2024-01-09T16:43:15.468935Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"<DigMontage | 0 extras (headshape), 0 HPIs, 3 fiducials, 128 channels>"},"metadata":{}}]},{"cell_type":"code","source":"mapping = {str(i): ch_name for i, ch_name in enumerate(montage.ch_names)}\ninfo.rename_channels(mapping)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:15.601963Z","iopub.execute_input":"2024-01-09T16:43:15.602416Z","iopub.status.idle":"2024-01-09T16:43:15.615114Z","shell.execute_reply.started":"2024-01-09T16:43:15.602374Z","shell.execute_reply":"2024-01-09T16:43:15.614402Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"<Info | 7 non-empty values\n bads: []\n ch_names: A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, ...\n chs: 128 EEG\n custom_ref_applied: False\n highpass: 0.0 Hz\n lowpass: 128.0 Hz\n meas_date: unspecified\n nchan: 128\n projs: []\n sfreq: 256.0 Hz\n>","text/html":"<table class=\"table table-hover table-striped table-sm table-responsive small\">\n    <tr>\n        <th>Measurement date</th>\n        \n        <td>Unknown</td>\n        \n    </tr>\n    <tr>\n        <th>Experimenter</th>\n        \n        <td>Unknown</td>\n        \n    </tr>\n        <th>Participant</th>\n        \n        <td>Unknown</td>\n        \n    </tr>\n    <tr>\n        <th>Digitized points</th>\n        \n        <td>Not available</td>\n        \n    </tr>\n    <tr>\n        <th>Good channels</th>\n        <td>128 EEG</td>\n    </tr>\n    <tr>\n        <th>Bad channels</th>\n        <td>None</td>\n    </tr>\n    <tr>\n        <th>EOG channels</th>\n        <td>Not available</td>\n    </tr>\n    <tr>\n        <th>ECG channels</th>\n        <td>Not available</td>\n    \n    <tr>\n        <th>Sampling frequency</th>\n        <td>256.00 Hz</td>\n    </tr>\n    \n    \n    <tr>\n        <th>Highpass</th>\n        <td>0.00 Hz</td>\n    </tr>\n    \n    \n    <tr>\n        <th>Lowpass</th>\n        <td>128.00 Hz</td>\n    </tr>\n    \n    \n</table>"},"metadata":{}}]},{"cell_type":"code","source":"mapping = {ch_name: 'eeg' for ch_name in montage.ch_names}\ninfo.set_channel_types(mapping)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:15.840695Z","iopub.execute_input":"2024-01-09T16:43:15.841867Z","iopub.status.idle":"2024-01-09T16:43:15.851096Z","shell.execute_reply.started":"2024-01-09T16:43:15.841830Z","shell.execute_reply":"2024-01-09T16:43:15.849958Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"<Info | 7 non-empty values\n bads: []\n ch_names: A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, ...\n chs: 128 EEG\n custom_ref_applied: False\n highpass: 0.0 Hz\n lowpass: 128.0 Hz\n meas_date: unspecified\n nchan: 128\n projs: []\n sfreq: 256.0 Hz\n>","text/html":"<table class=\"table table-hover table-striped table-sm table-responsive small\">\n    <tr>\n        <th>Measurement date</th>\n        \n        <td>Unknown</td>\n        \n    </tr>\n    <tr>\n        <th>Experimenter</th>\n        \n        <td>Unknown</td>\n        \n    </tr>\n        <th>Participant</th>\n        \n        <td>Unknown</td>\n        \n    </tr>\n    <tr>\n        <th>Digitized points</th>\n        \n        <td>Not available</td>\n        \n    </tr>\n    <tr>\n        <th>Good channels</th>\n        <td>128 EEG</td>\n    </tr>\n    <tr>\n        <th>Bad channels</th>\n        <td>None</td>\n    </tr>\n    <tr>\n        <th>EOG channels</th>\n        <td>Not available</td>\n    </tr>\n    <tr>\n        <th>ECG channels</th>\n        <td>Not available</td>\n    \n    <tr>\n        <th>Sampling frequency</th>\n        <td>256.00 Hz</td>\n    </tr>\n    \n    \n    <tr>\n        <th>Highpass</th>\n        <td>0.00 Hz</td>\n    </tr>\n    \n    \n    <tr>\n        <th>Lowpass</th>\n        <td>128.00 Hz</td>\n    </tr>\n    \n    \n</table>"},"metadata":{}}]},{"cell_type":"code","source":"#info.set_montage(montage, on_missing='warn')","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:16.057755Z","iopub.execute_input":"2024-01-09T16:43:16.058204Z","iopub.status.idle":"2024-01-09T16:43:16.064451Z","shell.execute_reply.started":"2024-01-09T16:43:16.058171Z","shell.execute_reply":"2024-01-09T16:43:16.063299Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"X.shape\nreshaped_data = X[1]\n#reshaped_data.shape\nX.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:16.230901Z","iopub.execute_input":"2024-01-09T16:43:16.231325Z","iopub.status.idle":"2024-01-09T16:43:16.239169Z","shell.execute_reply.started":"2024-01-09T16:43:16.231290Z","shell.execute_reply":"2024-01-09T16:43:16.238045Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"(400, 128, 512)"},"metadata":{}}]},{"cell_type":"code","source":"mean_data = np.mean(X, axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:16.365661Z","iopub.execute_input":"2024-01-09T16:43:16.366073Z","iopub.status.idle":"2024-01-09T16:43:16.396127Z","shell.execute_reply.started":"2024-01-09T16:43:16.366038Z","shell.execute_reply":"2024-01-09T16:43:16.395162Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Create a RawArray object using reshaped data\nraw = mne.io.RawArray(X[1], info)\n\n# Plot the sensors with the applied montage\n#fig = raw.plot_sensors(show_names=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:16.511426Z","iopub.execute_input":"2024-01-09T16:43:16.511802Z","iopub.status.idle":"2024-01-09T16:43:16.523112Z","shell.execute_reply.started":"2024-01-09T16:43:16.511772Z","shell.execute_reply":"2024-01-09T16:43:16.521925Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"#raw.plot(n_channels=50, color = 'steelblue',show_scrollbars= False, show_scalebars= False, time_format=\"float\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:17.114183Z","iopub.execute_input":"2024-01-09T16:43:17.115415Z","iopub.status.idle":"2024-01-09T16:43:17.119567Z","shell.execute_reply.started":"2024-01-09T16:43:17.115374Z","shell.execute_reply":"2024-01-09T16:43:17.118420Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"import mne\nimport numpy as np\n\n# Assuming 'raw' is your Raw object\n\n# Number of time segments\nnum_segments = 4\nsegment_size = raw.n_times // num_segments\n\n# Plot topoplots for each segment\nfor i in range(num_segments):\n    start_idx = i * segment_size\n    end_idx = (i + 1) * segment_size if i < num_segments - 1 else raw.n_times\n    mean_data = np.mean(raw.get_data()[:, start_idx:end_idx], axis=1)\n    \n    info = raw.info\n\n    #mne.viz.plot_topomap(mean_data, info, show=True, contours= True, res=300, sensors='k.', size=5, vlim =(-0.00001,0.00001))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:17.416593Z","iopub.execute_input":"2024-01-09T16:43:17.417012Z","iopub.status.idle":"2024-01-09T16:43:17.429086Z","shell.execute_reply.started":"2024-01-09T16:43:17.416976Z","shell.execute_reply":"2024-01-09T16:43:17.428009Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"#plt.plot(X[1,:,:]);","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:17.471512Z","iopub.execute_input":"2024-01-09T16:43:17.472495Z","iopub.status.idle":"2024-01-09T16:43:17.475741Z","shell.execute_reply.started":"2024-01-09T16:43:17.472459Z","shell.execute_reply":"2024-01-09T16:43:17.474941Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"X_resize = X * (10**4)\n#plt.plot(X_resize[1,:,:]);","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:17.940381Z","iopub.execute_input":"2024-01-09T16:43:17.941413Z","iopub.status.idle":"2024-01-09T16:43:18.012232Z","shell.execute_reply.started":"2024-01-09T16:43:17.941364Z","shell.execute_reply":"2024-01-09T16:43:18.011283Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:43:18.017801Z","iopub.execute_input":"2024-01-09T16:43:18.018135Z","iopub.status.idle":"2024-01-09T16:43:18.025061Z","shell.execute_reply.started":"2024-01-09T16:43:18.018106Z","shell.execute_reply":"2024-01-09T16:43:18.023797Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"(400, 4)"},"metadata":{}}]},{"cell_type":"markdown","source":"## 2. Implement CNN","metadata":{}},{"cell_type":"code","source":"Y_1.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:44:12.210728Z","iopub.execute_input":"2024-01-09T16:44:12.211117Z","iopub.status.idle":"2024-01-09T16:44:12.218215Z","shell.execute_reply.started":"2024-01-09T16:44:12.211086Z","shell.execute_reply":"2024-01-09T16:44:12.216874Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"(200, 4)"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# Assuming X_1, X_2, Y_1, Y_2 are your datasets with four labels\n\n# Perform train-test split for X_1 and Y_1\nX_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, Y_1, test_size=0.2, random_state=0)\n\n# Perform train-test split for X_2 and Y_2\nX_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, Y_2, test_size=0.2, random_state=0)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:44:51.409223Z","iopub.execute_input":"2024-01-09T16:44:51.409656Z","iopub.status.idle":"2024-01-09T16:44:51.483176Z","shell.execute_reply.started":"2024-01-09T16:44:51.409619Z","shell.execute_reply":"2024-01-09T16:44:51.482005Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# Combine the results for X and Y for the test set\nX_test = np.concatenate((X_test_1, X_test_2), axis=0)\ny_test = np.concatenate((y_test_1, y_test_2), axis=0)\n\nX_train_ = np.concatenate((X_train_1, X_train_2), axis=0)\ny_train_ = np.concatenate((y_train_1, y_train_2), axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:44:55.019089Z","iopub.execute_input":"2024-01-09T16:44:55.019481Z","iopub.status.idle":"2024-01-09T16:44:55.106153Z","shell.execute_reply.started":"2024-01-09T16:44:55.019450Z","shell.execute_reply":"2024-01-09T16:44:55.105068Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"# Perform train-validation split for the combined training set\nX_train, X_val, y_train, y_val = train_test_split(X_train_, y_train_, test_size=0.1,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:45:04.565570Z","iopub.execute_input":"2024-01-09T16:45:04.565952Z","iopub.status.idle":"2024-01-09T16:45:04.623838Z","shell.execute_reply.started":"2024-01-09T16:45:04.565921Z","shell.execute_reply":"2024-01-09T16:45:04.622860Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"# split data into train and test set\n#X_train_, X_test, y_train_, y_test = train_test_split(X_resize, y, test_size=0.2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming X_train and y_train are your training data\n#X_train, X_val, y_train, y_val = train_test_split(X_train_, y_train_, test_size=0.1, random_state=0)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:27:39.390452Z","iopub.execute_input":"2024-01-09T16:27:39.390839Z","iopub.status.idle":"2024-01-09T16:27:39.475609Z","shell.execute_reply.started":"2024-01-09T16:27:39.390807Z","shell.execute_reply":"2024-01-09T16:27:39.474575Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"Y_2[:5]","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:47:58.658209Z","iopub.execute_input":"2024-01-09T16:47:58.658765Z","iopub.status.idle":"2024-01-09T16:47:58.666561Z","shell.execute_reply.started":"2024-01-09T16:47:58.658720Z","shell.execute_reply":"2024-01-09T16:47:58.665246Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"array([[351788,      1,      1,      1],\n       [358546,      1,      1,      1],\n       [365390,      3,      1,      1],\n       [372216,      3,      1,      1],\n       [387985,      3,      1,      1]])"},"metadata":{}}]},{"cell_type":"code","source":"# Sum the occurrences of True values along each column\nclass_counts = y_test.sum()\n\n# Plot the distribution\nplt.figure(figsize=(10, 6))\nsns.barplot(x=class_counts.index, y=class_counts.values)\nplt.title('Distribution of Classes in the Test Set')\nplt.xlabel('Class Index')\nplt.ylabel('Count')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-09T16:45:15.246595Z","iopub.execute_input":"2024-01-09T16:45:15.246990Z","iopub.status.idle":"2024-01-09T16:45:15.301035Z","shell.execute_reply.started":"2024-01-09T16:45:15.246960Z","shell.execute_reply":"2024-01-09T16:45:15.299639Z"},"trusted":true},"execution_count":70,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[70], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the distribution\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m sns\u001b[38;5;241m.\u001b[39mbarplot(x\u001b[38;5;241m=\u001b[39m\u001b[43mclass_counts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m, y\u001b[38;5;241m=\u001b[39mclass_counts\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution of Classes in the Test Set\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass Index\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'index'"],"ename":"AttributeError","evalue":"'numpy.int64' object has no attribute 'index'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"'''Adam_ = tf.keras.optimizers.Adam(learning_rate=0.0001, weight_decay=0.001)\n\n\ndef create_cnn(input_shape):\n    # create model - Sequential class, linear stack of layers can be added\n    model = models.Sequential()\n    # first layer \n    model.add(layers.Conv2D(32, kernel_size = (1,5), padding = 'valid', activation='relu', input_shape = input_shape, strides = (1,2)))\n    # adds max pooling layer\n    model.add(layers.MaxPooling2D(pool_size=(1, 2)))\n    # second layer\n    model.add(layers.Conv2D(32, kernel_size = (1,5), padding = 'valid', activation='relu'))\n    # adds max pooling layer\n    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n    # flatten output before last convolutional layer\n    model.add(layers.Flatten())\n    # Add a fully connected layer \n    model.add(layers.Dense(3000, activation='relu'))\n    # Add Dropout for regularization\n    model.add(layers.Dropout(0.5)) # 0.2 is the default\n    # Output layer \n    model.add(layers.Dense(4, activation='softmax'))\n\n    # Compile model\n    model.compile( \n        optimizer = 'adam', \n        loss = 'categorical_crossentropy',\n        metrics = ['accuracy'],\n        )    \n    \n    return model\n\nmodel = create_cnn(input_shape)\n\nmodel.summary() \n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Adam_ = tf.keras.optimizers.Adam(learning_rate=0.001, weight_decay=0.0001)\n# L1_ = tf.keras.regularizers.L1(l1=0.0005)\n\ndef create_cnn(input_shape):\n    # create model - Sequential class, linear stack of layers can be added\n    model = models.Sequential()\n    # first layer\n    model.add(layers.Conv2D(32, kernel_size = (1,31), padding = 'valid', activation='relu', input_shape= input_shape, strides = (1,1)))\n    # adds max pooling layer\n    model.add(layers.MaxPooling2D(pool_size=(1, 2)))\n    # second layer\n#     model.add(layers.Conv2D(8, kernel_size = (128,1), padding = 'valid', activation='relu', input_shape= input_shape, strides = (1,1)))    \n    # depthwise layer\n    model.add(layers.DepthwiseConv2D((128,1), padding = 'valid', activation='relu'))\n    # adds max pooling layer\n#     model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n    # flatten output before last convolutional layer\n    model.add(layers.Flatten())\n    # Add a fully connected layer \n    model.add(layers.Dense(200, activation='relu')) \n    # Add Dropout for regularization\n    model.add(layers.Dropout(0.5)) # 0.2 is the default\n    # Add a second fully connected layer \n    model.add(layers.Dense(50, activation='relu')) \n    # Add Dropout for regularization\n    model.add(layers.Dropout(0.5))\n    # Output layer \n    model.add(layers.Dense(4, activation='softmax'))\n\n    # Compile model\n    model.compile( \n        optimizer = Adam_, # default\n        loss = 'categorical_crossentropy',\n        metrics = ['accuracy'],\n        )    \n    \n    return model\n\nmodel = create_cnn(input_shape)\n\nmodel.summary()       ","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:55:03.816621Z","iopub.execute_input":"2024-01-09T13:55:03.817813Z","iopub.status.idle":"2024-01-09T13:55:04.174255Z","shell.execute_reply.started":"2024-01-09T13:55:03.817757Z","shell.execute_reply":"2024-01-09T13:55:04.173029Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 128, 482, 32)      1024      \n                                                                 \n max_pooling2d (MaxPooling2  (None, 128, 241, 32)      0         \n D)                                                              \n                                                                 \n depthwise_conv2d (Depthwis  (None, 1, 241, 32)        4128      \n eConv2D)                                                        \n                                                                 \n flatten (Flatten)           (None, 7712)              0         \n                                                                 \n dense (Dense)               (None, 200)               1542600   \n                                                                 \n dropout (Dropout)           (None, 200)               0         \n                                                                 \n dense_1 (Dense)             (None, 50)                10050     \n                                                                 \n dropout_1 (Dropout)         (None, 50)                0         \n                                                                 \n dense_2 (Dense)             (None, 4)                 204       \n                                                                 \n=================================================================\nTotal params: 1558006 (5.94 MB)\nTrainable params: 1558006 (5.94 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## EEGNET Version","metadata":{}},{"cell_type":"code","source":"def EEGNet(input_shape): \n    model = models.Sequential()\n    \n    model.add(layers.Conv2D(8, kernel_size = (1,64), padding = 'same', input_shape = input_shape))\n    model.add(layers.BatchNormalization())\n    \n    model.add(layers.DepthwiseConv2D((128,1), depth_multiplier = 2, depthwise_constraint = max_norm(1.)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Activation('relu'))\n    model.add(layers.AveragePooling2D(pool_size=(1, 4)))    \n    model.add(layers.SpatialDropout2D(0.25))\n    \n    model.add(layers.SeparableConv2D(16, kernel_size = (1,16), padding = 'same'))\n    model.add(layers.BatchNormalization()) \n    model.add(layers.Activation('relu'))\n    model.add(layers.AveragePooling2D(pool_size=(1, 8)))    \n    model.add(layers.SpatialDropout2D(0.25))\n              \n    model.add(layers.Flatten())\n    model.add(layers.Dense(4, activation='softmax'))\n    \n    # Compile model\n    model.compile( \n        optimizer = 'adam', # default\n        loss = 'categorical_crossentropy',\n        metrics = ['accuracy'],\n        ) \n              \n    return model\n\nmodel = EEGNet(input_shape)\n\nmodel.summary() \n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:55:06.759618Z","iopub.execute_input":"2024-01-09T13:55:06.760120Z","iopub.status.idle":"2024-01-09T13:55:07.033535Z","shell.execute_reply.started":"2024-01-09T13:55:06.760082Z","shell.execute_reply":"2024-01-09T13:55:07.032033Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_1 (Conv2D)           (None, 128, 512, 8)       520       \n                                                                 \n batch_normalization (Batch  (None, 128, 512, 8)       32        \n Normalization)                                                  \n                                                                 \n depthwise_conv2d_1 (Depthw  (None, 1, 512, 16)        2064      \n iseConv2D)                                                      \n                                                                 \n batch_normalization_1 (Bat  (None, 1, 512, 16)        64        \n chNormalization)                                                \n                                                                 \n activation (Activation)     (None, 1, 512, 16)        0         \n                                                                 \n average_pooling2d (Average  (None, 1, 128, 16)        0         \n Pooling2D)                                                      \n                                                                 \n spatial_dropout2d (Spatial  (None, 1, 128, 16)        0         \n Dropout2D)                                                      \n                                                                 \n separable_conv2d (Separabl  (None, 1, 128, 16)        528       \n eConv2D)                                                        \n                                                                 \n batch_normalization_2 (Bat  (None, 1, 128, 16)        64        \n chNormalization)                                                \n                                                                 \n activation_1 (Activation)   (None, 1, 128, 16)        0         \n                                                                 \n average_pooling2d_1 (Avera  (None, 1, 16, 16)         0         \n gePooling2D)                                                    \n                                                                 \n spatial_dropout2d_1 (Spati  (None, 1, 16, 16)         0         \n alDropout2D)                                                    \n                                                                 \n flatten_1 (Flatten)         (None, 256)               0         \n                                                                 \n dense_3 (Dense)             (None, 4)                 1028      \n                                                                 \n=================================================================\nTotal params: 4300 (16.80 KB)\nTrainable params: 4220 (16.48 KB)\nNon-trainable params: 80 (320.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Early Stopping    \nEarlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n\n# Reduce Learning Rate\nReduceLR = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.1,\n    patience=3,\n    mode='auto',\n    min_lr=0.00001,\n)\n\n# Train model \ndef fit_evaluate(X_train, X_val,  y_train, y_val, epochs = 50, batch_size = 16): \n    model = create_cnn(input_shape)\n    results = model.fit(X_train, y_train, epochs, batch_size, verbose= 1, callbacks=[EarlyStopping, ReduceLR], validation_split = 0.1)\n    print(\"Val Score: \", model.evaluate(X_val, y_val))\n    \n    return results\n","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:55:09.661546Z","iopub.execute_input":"2024-01-09T13:55:09.661985Z","iopub.status.idle":"2024-01-09T13:55:09.671426Z","shell.execute_reply.started":"2024-01-09T13:55:09.661953Z","shell.execute_reply":"2024-01-09T13:55:09.670029Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# first model\nmodel_history1 = fit_evaluate(X_train, X_val, y_train, y_val, epochs = 50, batch_size = 16)","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:55:12.588797Z","iopub.execute_input":"2024-01-09T13:55:12.589335Z","iopub.status.idle":"2024-01-09T13:57:37.484939Z","shell.execute_reply.started":"2024-01-09T13:55:12.589297Z","shell.execute_reply":"2024-01-09T13:57:37.483849Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Epoch 1/16\n6/6 [==============================] - 18s 3s/step - loss: 1.3864 - accuracy: 0.2703 - val_loss: 1.4188 - val_accuracy: 0.0345 - lr: 0.0010\nEpoch 2/16\n6/6 [==============================] - 15s 2s/step - loss: 1.3836 - accuracy: 0.2857 - val_loss: 1.4145 - val_accuracy: 0.0345 - lr: 0.0010\nEpoch 3/16\n6/6 [==============================] - 15s 2s/step - loss: 1.3669 - accuracy: 0.2896 - val_loss: 1.4330 - val_accuracy: 0.0345 - lr: 0.0010\nEpoch 4/16\n6/6 [==============================] - 15s 2s/step - loss: 1.3799 - accuracy: 0.2780 - val_loss: 1.4108 - val_accuracy: 0.0345 - lr: 0.0010\nEpoch 5/16\n6/6 [==============================] - 15s 2s/step - loss: 1.3564 - accuracy: 0.3591 - val_loss: 1.4921 - val_accuracy: 0.0345 - lr: 0.0010\nEpoch 6/16\n6/6 [==============================] - 15s 2s/step - loss: 1.3390 - accuracy: 0.3475 - val_loss: 1.4979 - val_accuracy: 0.0345 - lr: 0.0010\nEpoch 7/16\n6/6 [==============================] - 15s 2s/step - loss: 1.3518 - accuracy: 0.3050 - val_loss: 1.4618 - val_accuracy: 0.1034 - lr: 0.0010\n1/1 [==============================] - 0s 388ms/step - loss: 1.4153 - accuracy: 0.1875\nVal Score:  [1.4152709245681763, 0.1875]\n","output_type":"stream"}]},{"cell_type":"code","source":"# second model\nmodel_history2 = fit_evaluate(X_train, X_val, y_train, y_val, epochs = 50, batch_size = 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history3 = fit_evaluate(X_train, X_val, y_train, y_val, 50, 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history4 = fit_evaluate(X_train, X_val, y_train, y_val, 50, 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history5 = fit_evaluate(X_train, X_val, y_train, y_val, 50, 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history6 = fit_evaluate(X_train, X_val, y_train, y_val, 50, 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history7 = fit_evaluate(X_train, X_val, y_train, y_val, 50, 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history8 = fit_evaluate(X_train, X_val, y_train, y_val, 50, 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history9 = fit_evaluate(X_train, X_val, y_train, y_val, 50, 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history10 = fit_evaluate(X_train, X_val, y_train, y_val, 50, 16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nplt.figure(figsize=(12, 8))\n\nsns.lineplot(x=range(1, len(model_history1.history['val_loss']) + 1), y=model_history1.history['val_loss'], label='Subj. 1')\nsns.lineplot(x=range(1, len(model_history2.history['val_loss']) + 1), y=model_history2.history['val_loss'], label='Subj. 2')\nsns.lineplot(x=range(1, len(model_history3.history['val_loss']) + 1), y=model_history3.history['val_loss'], label='Subj. 3')\nsns.lineplot(x=range(1, len(model_history4.history['val_loss']) + 1), y=model_history4.history['val_loss'], label='Subj. 4')\nsns.lineplot(x=range(1, len(model_history5.history['val_loss']) + 1), y=model_history5.history['val_loss'], label='Subj. 5')\nsns.lineplot(x=range(1, len(model_history6.history['val_loss']) + 1), y=model_history6.history['val_loss'], label='Subj. 6')\nsns.lineplot(x=range(1, len(model_history7.history['val_loss']) + 1), y=model_history7.history['val_loss'], label='Subj. 7')\nsns.lineplot(x=range(1, len(model_history8.history['val_loss']) + 1), y=model_history8.history['val_loss'], label='Subj. 8')\nsns.lineplot(x=range(1, len(model_history9.history['val_loss']) + 1), y=model_history9.history['val_loss'], label='Subj. 9')\nsns.lineplot(x=range(1, len(model_history10.history['val_loss']) + 1), y=model_history10.history['val_loss'], label='Subj. 10')\n\n\nplt.title('Visual Condition - Validation Loss Comparison Across Subjects - CNN')\nplt.xlabel('Epochs')\nplt.ylabel('Validation Loss')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\n\nsns.lineplot(x=range(1, len(model_history1.history['val_accuracy']) + 1), y=model_history1.history['val_accuracy'], label='Subj. 1')\nsns.lineplot(x=range(1, len(model_history2.history['val_accuracy']) + 1), y=model_history2.history['val_accuracy'], label='Subj. 2')\nsns.lineplot(x=range(1, len(model_history3.history['val_accuracy']) + 1), y=model_history3.history['val_accuracy'], label='Subj. 3')\nsns.lineplot(x=range(1, len(model_history4.history['val_accuracy']) + 1), y=model_history4.history['val_accuracy'], label='Subj. 4')\nsns.lineplot(x=range(1, len(model_history5.history['val_accuracy']) + 1), y=model_history5.history['val_accuracy'], label='Subj. 5')\nsns.lineplot(x=range(1, len(model_history6.history['val_accuracy']) + 1), y=model_history6.history['val_accuracy'], label='Subj. 6')\nsns.lineplot(x=range(1, len(model_history7.history['val_accuracy']) + 1), y=model_history7.history['val_accuracy'], label='Subj. 7')\nsns.lineplot(x=range(1, len(model_history8.history['val_accuracy']) + 1), y=model_history8.history['val_accuracy'], label='Subj. 8')\nsns.lineplot(x=range(1, len(model_history9.history['val_accuracy']) + 1), y=model_history9.history['val_accuracy'], label='Subj. 9')\nsns.lineplot(x=range(1, len(model_history10.history['val_accuracy']) + 1), y=model_history10.history['val_accuracy'], label='Subj. 10')\n\nplt.title('Visual Condition - Validation Accuracy Comparison Across Subjects - CNN')\nplt.xlabel('Epochs')\nplt.ylabel('Validation Accuracy')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 16))\n\n# Plot Validation Loss\nplt.subplot(3, 2, 1)\nfor i in range(1, 11):\n    sns.lineplot(x=range(1, len(locals()[f'model_history{i}'].history['val_loss']) + 1),\n                 y=locals()[f'model_history{i}'].history['val_loss'], label=f'Subj. {i}')\n\nplt.title('Visual Condition - Validation Loss Across Subjects - CNN')\nplt.xlabel('Epochs')\nplt.ylabel('Validation Loss')\nplt.legend()\n\n# Plot Validation Accuracy\nplt.subplot(3, 2, 2)\nfor i in range(1, 11):\n    sns.lineplot(x=range(1, len(locals()[f'model_history{i}'].history['val_accuracy']) + 1),\n                 y=locals()[f'model_history{i}'].history['val_accuracy'], label=f'Subj. {i}')\n\nplt.title('Visual Condition - Validation Accuracy Subjects - CNN')\nplt.xlabel('Epochs')\nplt.ylabel('Validation Accuracy')\nplt.legend()\n\n# Plot Training Loss\nplt.subplot(3, 2, 3)\nfor i in range(1, 11):\n    sns.lineplot(x=range(1, len(locals()[f'model_history{i}'].history['loss']) + 1),\n                 y=locals()[f'model_history{i}'].history['loss'], label=f'Subj. {i}')\n\nplt.title('Visual Condition - Training Loss Across Subjects - CNN')\nplt.xlabel('Epochs')\nplt.ylabel('Training Loss')\nplt.legend()\n\n# Plot Training Accuracy\nplt.subplot(3, 2, 4)\nfor i in range(1, 11):\n    sns.lineplot(x=range(1, len(locals()[f'model_history{i}'].history['accuracy']) + 1),\n                 y=locals()[f'model_history{i}'].history['accuracy'], label=f'Subj. {i}')\n\nplt.title('Visual Condition - Training Accuracy Across Subjects - CNN')\nplt.xlabel('Epochs')\nplt.ylabel('Training Accuracy')\nplt.legend()\n\nplt.tight_layout()\n# Save the figure\nplt.savefig('comparison_plot_EEGNet.png')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_folds = 5\nepochs = 50\nbatch_size = 16\n\nskf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=0)\ntrain_fold = []\nval_fold = []\nmodel_history = []\n\nfor train_ind, val_ind in skf.split(X_train, np.argmax(y_train, axis=1)):\n    train_fold.append(train_ind)\n    val_fold.append(val_ind)\n\nfor i in range(n_folds):\n    print(\"Training on Fold: \", i + 1)\n    \n    X_train_i = X_train[train_fold[i]]\n    y_train_i = y_train.values[train_fold[i]]  # Convert to NumPy array\n    \n    X_val_i = X_train[val_fold[i]]\n    y_val_i = y_train.values[val_fold[i]]  # Convert to NumPy array\n    \n    model_history.append(fit_evaluate(X_train_i, X_val_i, y_train_i, y_val_i, epochs, batch_size))\n    \n    print(\"=======\" * 12, end=\"\\n\\n\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 8))\n\nfor i, history in enumerate(histories):\n    plt.plot(history.history['val_loss'], label=f'Model {i+1}')\n\nplt.title('Validation Loss Comparison')\nplt.xlabel('Epochs')\nplt.ylabel('Validation Loss')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the fold with the best validation accuracy\nbest_fold_idx = np.argmax([np.max(model_history[i].history['val_accuracy']) for i in range(n_folds)])\n\n# Create subplots\nfig, ax = plt.subplots(nrows=1, ncols=2)\n\n# Plot the best fold\nax[0].plot(model_history[best_fold_idx].history['accuracy'], label=f'Fold {best_fold_idx + 1} Train')\nax[0].plot(model_history[best_fold_idx].history['val_accuracy'], label=f'Fold {best_fold_idx + 1} Validation')\n\nax[1].plot(model_history[best_fold_idx].history['loss'], label=f'Fold {best_fold_idx + 1} Train')\nax[1].plot(model_history[best_fold_idx].history['val_loss'], label=f'Fold {best_fold_idx + 1} Validation')\n\n# Set common titles and labels\nax[0].set_title('Model Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(loc='upper left')\n\nax[1].set_title('Model Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(loc='upper left')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize history\n# Loss\nfor i in range(n_folds):\n    plt.plot(model_history[i].history['val_loss'], label=f'Training Fold {i + 1}')\n\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Loss Value')\nplt.show()\n\n\n# Validation Accuracy\nfor i in range(n_folds):\n    plt.plot(model_history[i].history['val_accuracy'], label=f'Training Fold {i + 1}')\n\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Validation Accuracy (%)')\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy\nfor i in range(n_folds):\n    plt.plot(model_history[i].history['accuracy'], label=f'Training Fold {i + 1}')\n\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy (%)')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%tensorboard --logdir logs/fit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_y = model.predict(\n    X_test,\n    verbose =1\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(pred_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(\n    X_test,\n    y_test,\n    batch_size = 24,\n    verbose =2\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}